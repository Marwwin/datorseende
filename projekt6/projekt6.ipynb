{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception in Tkinter callback\nTraceback (most recent call last):\n  File \"/home/marwwin/.anaconda3/lib/python3.8/tkinter/__init__.py\", line 1883, in __call__\n    return self.func(*args)\n  File \"<ipython-input-1-c39f18347f45>\", line 20, in detect_face\n    img = ImageTk.PhotoImage(image=PIL.Image.fromarray(face_img))\nNameError: name 'PIL' is not defined\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "def detect_face(img):\n",
    "    global face_cascade, bottomFrame\n",
    "    vc = cv2.VideoCapture(0)\n",
    "    if vc.isOpened():\n",
    "        rval, frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "\n",
    "    while rval:\n",
    "        rval, frame = vc.read()\n",
    "        face_img = frame.copy()   \n",
    "        face_rect = face_cascade.detectMultiScale(face_img, scaleFactor = 1.2,minNeighbors = 5) \n",
    "        for (x, y, w, h) in face_rect: \n",
    "            cv2.rectangle(face_img, (x, y),  (x + w, y + h), (0, 255, 0), 2) \n",
    "        img = ImageTk.PhotoImage(image=PIL.Image.fromarray(face_img))\n",
    "        lmain.img = img\n",
    "        lmain.configure(image=img)\n",
    "        \n",
    "        #canvas.create_image(20, 20, anchor=NW, image=img) \n",
    "        \n",
    "        key = cv2.waitKey(20)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml') \n",
    "\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "topFrame = Frame(root)\n",
    "topFrame.pack()\n",
    "bottomFrame = Frame(root)\n",
    "bottomFrame.pack(side=BOTTOM)\n",
    "lmain = Label(bottomFrame)\n",
    "lmain.pack()\n",
    "#canvas = Canvas(bottomFrame,width=400,height=400)\n",
    "#canvas.pack()\n",
    "#\n",
    "\n",
    "btn1 = Button(topFrame, text=\"btn1\",fg=\"red\")\n",
    "btn2 = Button(topFrame, text=\"btn2\",fg=\"red\" )\n",
    "btn3 = Button(topFrame, text=\"btn3\",fg=\"red\" )\n",
    "btn4 = Button(topFrame, text=\"btn4\",fg=\"red\" )\n",
    "\n",
    "btn1.pack(side=LEFT)\n",
    "btn1.bind(\"<Button-1>\",detect_face)\n",
    "btn2.pack(side=LEFT)\n",
    "btn3.pack(side=LEFT)\n",
    "btn4.pack(side=LEFT)\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "#\n",
    "#label = tk.Label(root)\n",
    "#img = Image.open(r\"faces/1.1.jpg\")\n",
    "#label.img = ImageTk.PhotoImage(img)\n",
    "#label['image'] = label.img\n",
    "#label.pack()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-8-37d1653db0a7>, line 4)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-37d1653db0a7>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    if vc.isOpened():\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required packages \n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# create a function to detect face \n",
    "def detect_face(img): \n",
    "    global face_cascade\n",
    "    face_img = img.copy()   \n",
    "    face_rect = face_cascade.detectMultiScale(face_img, scaleFactor = 1.2,minNeighbors = 5) \n",
    "    for (x, y, w, h) in face_rect: \n",
    "        cv2.rectangle(face_img, (x, y),  (x + w, y + h), (0, 255, 0), 2) \n",
    "    return face_img \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml') \n",
    "\n",
    "cv2.namedWindow(\"main\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "if vc.isOpened():\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    detected_frame = detect_face(frame)\n",
    "    cv2.imshow(\"main\",detected_frame)\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "t = input(\"\")\n",
    "print(t == \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "def capture_face(img): \n",
    "    global face_cascade, sampleN, id\n",
    "    face_img = img.copy()   \n",
    "    face_rect = face_cascade.detectMultiScale(face_img, scaleFactor = 1.2,minNeighbors = 5) \n",
    "    offset = 30\n",
    "    for (x, y, w, h) in face_rect: \n",
    "        sampleN=sampleN+1\n",
    "        if not cv2.imwrite(\"faces/\"+str(id)+ \".\" +str(sampleN)+ \".png\", face_img[y-offset:y+h+offset, x-offset:x+w+offset]):\n",
    "            raise Exception(\"Could not write image\")\n",
    "        cv2.rectangle(face_img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        #cv2.waitKey(0)\n",
    "    return face_img \n",
    "\n",
    "sampleN=0\n",
    "id = input('enter user id')\n",
    "\n",
    "if id == \"\":\n",
    "    print(\"No ID exiting...\")\n",
    "else:\n",
    "    face_cascade = cv2.CascadeClassifier    (cv2.data.haarcascades+'haarcascade_frontalface_default.xml') \n",
    "    cv2.namedWindow(\"main\")\n",
    "    vc = cv2.VideoCapture(0) \n",
    "    vc.set(cv2.CAP_PROP_BUFFERSIZE, 1) # Set buffersizen till 1 så man kan få den nyaste framen från kameran\n",
    "    if vc.isOpened():\n",
    "        rval, frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "    \n",
    "    while rval:\n",
    "        key = cv2.waitKey(0)\n",
    "        rval, frame = vc.read()\n",
    "        detected_frame = capture_face(frame)\n",
    "        cv2.imshow(\"main\",detected_frame)\n",
    "        if sampleN > 10:\n",
    "            break\n",
    "    print(rval)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2 2 2 1 2 2 1 2 2 2 1 2 2 1 1 1 1 1 2 2 2 1\n 1 2 1 2 2 2 2 1 2 2 1 2 1 1 1 2 1 1 1 1 1 2 2 2 2 1 1 2 2 2 1 2 2 1 1 1 1\n 2 1 1 2 2 2 2 1 2 2 2 2 2 1 1 1 2 2 1 1 1 1 1 2 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "path=\"faces/\"\n",
    "\n",
    "def getImagesWithID(path):\n",
    "    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]   \n",
    "    faces = []\n",
    "    IDs = []\n",
    "    for imagePath in imagePaths:      \n",
    "        facesImg = Image.open(imagePath).convert('L')\n",
    "        faceNP = np.array(facesImg).astype('uint8')\n",
    "        ID= int(os.path.split(imagePath)[1][0])\n",
    "        faces.append(faceNP)\n",
    "        IDs.append(ID)\n",
    "        cv2.imshow(\"Adding faces for traning\",faceNP)\n",
    "        cv2.waitKey(10)\n",
    "    return np.array(IDs), faces\n",
    "\n",
    "Ids,faces  = getImagesWithID(path)\n",
    "print(Ids)\n",
    "recognizer.train(faces, Ids)\n",
    "recognizer.write(\"trainingdata.yml\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required packages \n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# create a function to detect face \n",
    "def detect_person(img): \n",
    "    global face_cascade\n",
    "    face_img = img.copy()   \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_rect = face_cascade.detectMultiScale(gray, scaleFactor = 1.2,minNeighbors = 5) \n",
    "    for (x, y, w, h) in face_rect:\n",
    "        name = \"\"\n",
    "        id,confusion = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        if id == 1:\n",
    "            name = \"Markus\"\n",
    "        elif id == 2:\n",
    "            name = \"Jonna\"\n",
    "        else:\n",
    "            name = str(id)\n",
    "        cv2.putText(face_img,name+\" \"+\"{0:.3}\".format(confusion),(x,y+h),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),2)\n",
    "        cv2.rectangle(face_img, (x, y),  (x + w, y + h), (0, 255, 0), 2) \n",
    "    return face_img \n",
    "\n",
    "def getImagesWithID(path):\n",
    "    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]   \n",
    "    faces = []\n",
    "    IDs = []\n",
    "    for imagePath in imagePaths:      \n",
    "        facesImg = Image.open(imagePath).convert('L')\n",
    "        faceNP = np.array(facesImg).astype('uint8')\n",
    "        ID= int(os.path.split(imagePath)[1][0])\n",
    "        faces.append(faceNP)\n",
    "        IDs.append(ID)\n",
    "        cv2.imshow(\"Adding faces for traning\",faceNP)\n",
    "        cv2.waitKey(10)\n",
    "    return np.array(IDs), faces\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml') \n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainingdata.yml\")\n",
    "cv2.namedWindow(\"main\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "if vc.isOpened():\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    detected_frame = detect_person(frame)\n",
    "    cv2.imshow(\"main\",detected_frame)\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27:\n",
    "        break\n",
    "vc = False\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "  \n",
    "  "
   ]
  }
 ]
}