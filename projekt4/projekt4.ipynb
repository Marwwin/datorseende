{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Datorseende Projekt 4 Markus Kankkonen\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Uppgift 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n"
   ]
  },
  {
   "source": [
    "- Vi definierar några funktioner\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterImageOnce(image,kernel,depth = -1,text = \"Filtered\",color=(0,0,250)):\n",
    "    print(image.shape)\n",
    "    filtered_image = copy.deepcopy(image)\n",
    "    copy_image = copy.deepcopy(image)\n",
    "    orig_img_text = cv2.putText(copy_image,\"Original\",(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,250),2)\n",
    "    filtered_image = cv2.filter2D(filtered_image,depth,kernel) \n",
    "    text_img = copy.deepcopy(filtered_image)\n",
    "    text_img = cv2.putText(text_img,text,(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,color,2)\n",
    "    joined_image = np.hstack((orig_img_text,text_img))   \n",
    "    showImage(joined_image)\n",
    "    return filtered_image\n",
    "\n",
    "def showImage(image,text=\"\",color=(0,0,250)):\n",
    "    text_img = copy.deepcopy(image)\n",
    "    text_img = cv2.putText(text_img,text,(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,color,2)\n",
    "    cv2.namedWindow(\"main\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('image', 900, 450) \n",
    "    cv2.imshow(\"main\",text_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "- Vi läser in våran bild"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= cv2.imread(\"bird.jpg\",0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(394, 700)\n"
     ]
    }
   ],
   "source": [
    "kernel_2D_laplacian = np.matrix([[0,-1.0,0],\n",
    "                                 [-1.0,5.0,-1.0],\n",
    "                                 [0,-1.0,0]]) \n",
    "f1 = filterImageOnce(image,kernel_2D_laplacian,text=\"Laplacian\")"
   ]
  },
  {
   "source": [
    "![title](laplacian.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Uppgift 2\n",
    "- Sobel edge detector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(394, 700)\n",
      "(394, 700)\n"
     ]
    }
   ],
   "source": [
    "kernel_sobel_hor = np.matrix([[1.0,2.0,1.0],\n",
    "                                 [0,0,0],\n",
    "                                 [-1.0,-2.0,-1.0]])\n",
    "\n",
    "kernel_sobel_ver = np.matrix([[-1.0,0,1.0],\n",
    "                                 [-2.0,0,2],\n",
    "                                 [-1.0,0,1.0]]) \n",
    "sobel_h = filterImageOnce(f1,kernel_sobel_hor,text=\"Sobel H + laplacian\",color=(250,0,0))\n",
    "sobel_v = filterImageOnce(f1,kernel_sobel_ver,text=\"Sobel V + laplacian\",color=(250,0,0))\n",
    "sobel_combined = cv2.bitwise_or(sobel_h,sobel_v)\n",
    "showImage(sobel_combined,text=\"Sobel Combined\",color=(250,250,250))\n"
   ]
  },
  {
   "source": [
    "![sobel](sobel_h.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![sobel](sobel_v.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![sobel](sobel_combined.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Dessa följande är först körda genom laplacian filtret före sobel.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![sobel+laplacian](sobel_laplacian_h.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![sobel+laplacian](sobel_laplacian_v.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Jag tycker orginal bilden fungerar bättre än den som är körd via laplacian filret.\n",
    "- med laplacian så blir det mycket mera noise\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- I  nästa cell körs cv2s egna sobel funktion \n",
    "- Resultaten blev väldigt lika vår egna sobel funktion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_image = copy.deepcopy(image)\n",
    "orig_img_text = cv2.putText(copy_image,\"Original\",(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,250),2)\n",
    "\n",
    "cv_sobel_h = cv2.Sobel(image,-1,1,0)\n",
    "cv_sobel_v = cv2.Sobel(image,-1,0,1)\n",
    "\n",
    "showImage(np.hstack((orig_img_text,cv_sobel_h)))\n",
    "showImage(np.hstack((orig_img_text,cv_sobel_v)))\n",
    "\n",
    "sobel_combined = cv2.bitwise_or(cv_sobel_h,cv_sobel_v)\n",
    "\n",
    "joined_image = np.hstack((orig_img_text,sobel_combined))   \n",
    "showImage(joined_image)\n",
    "\n",
    "#showImage(sobel_combined)\n"
   ]
  },
  {
   "source": [
    "![sobel_cv](cv_sobel_h.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![sobel_cv](cv_sobel_v.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![sobel](cv_sobel_combine.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Canny edgedetection\n",
    "- Här använder vi canny "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_image = copy.deepcopy(image)\n",
    "orig_img_text = cv2.putText(copy_image,\"Original\",(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,250),2)\n",
    "canny = cv2.Canny(image,250,270)\n",
    "joined_image = np.hstack((orig_img_text,canny))   \n",
    "showImage(joined_image)\n"
   ]
  },
  {
   "source": [
    "![canny](canny_oirg.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Canny Algoritmen tycks göra ett mycket bättre job än sobel. \n",
    "- Den är mycket mera möjligheter att ställa in.\n",
    "- Bilden blir nästan som ur en teckand serie. Skarpa linjer och mörk bakrund"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## En modifierad filterImage funktion för den sista uppgiften\n",
    "def filterImage(image,kernel,depth = -1):\n",
    "    filtered_image = copy.deepcopy(image)\n",
    "    copy_image = copy.deepcopy(image)\n",
    "    orig_img_text = cv2.putText(copy_image,\"Original\",(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,250),2)\n",
    "    filtered_image = cv2.filter2D(filtered_image,depth,kernel) \n",
    "    text = \"\"\n",
    "    text_img = copy.deepcopy(filtered_image)\n",
    "    text_img = cv2.putText(text_img,text,(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,250),2)\n",
    "    joined_image = np.hstack((orig_img_text,text_img))   \n",
    "    return filtered_image\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### uppg 4\n",
    "- Jag satt så många timmar och skruvade på dethär så ja börjar bli helt snurrig på edgedetection. I slutändan så veta ja inte mera vad som är bra eller inte :)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2D_laplacian = np.matrix([[0,-1.0,0],\n",
    "                                 [-1.0,5.0,-1.0],\n",
    "                                 [0,-1.0,0]])\n",
    "kernel_hpf = np.matrix([[-1.0,-1.0,-1.0],\n",
    "                                 [-1.0,9.0,-1.0],\n",
    "                                 [-1.0,-1.0,-1.0]]) *1\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit = 8,tileGridSize=(11,11)) \n",
    "clahe2 = cv2.createCLAHE(clipLimit = 4,tileGridSize=(35,35)) \n",
    "\n",
    "\n",
    "face = cv2.imread(\"face.jpg\",0)\n",
    "\n",
    "face2 = cv2.medianBlur(face, 13)\n",
    "\n",
    "face2 =  filterImage(face2,kernel_2D_laplacian)\n",
    "#face3 =(cv2.equalizeHist(face2))\n",
    "face3 = clahe.apply(face2)\n",
    "face32 = clahe2.apply(face2)\n",
    "#showImage(face3)\n",
    "#face3 = filterImage(face3,kernel_2D_laplacian)\n",
    "\n",
    "#face3 = cv2.GaussianBlur(face2,(5,5),1)\n",
    "#showImage(face3)\n",
    "\n",
    "#face3_sob_h = cv2.Sobel(face3,0,1,0,cv2.CV_64F)\n",
    "#face3_sob_v = cv2.Sobel(face3,0,0,1,cv2.CV_64F)\n",
    "#face4 = cv2.bitwise_or(face3_sob_h,face3_sob_v)\n",
    "#\n",
    "#face5_sob_h = cv2.Sobel(face3,0,1,0,cv2.CV_64F)\n",
    "#face5_sob_v = cv2.Sobel(face3,0,0,1,cv2.CV_64F)\n",
    "#face5 = cv2.bitwise_or(face5_sob_h,face5_sob_v)\n",
    "#med = cv2.Canny(face3,90,90,5,L2gradient=False)\n",
    "#med = cv2.Canny(face3,55,55,5,L2gradient=True)\n",
    "#showImage(face3_sob_h)\n",
    "#showImage(med)\n",
    "\n",
    "med = cv2.Canny(thresh1,900,1850,apertureSize=5,L2gradient=False)\n",
    "two = cv2.Canny(face32,1000,1150,apertureSize=5,L2gradient=False)\n",
    "face5 = cv2.bitwise_or(med,two)\n",
    "\n",
    "copy_image = copy.deepcopy(face)\n",
    "orig_img_text = cv2.putText(copy_image,\"Original\",(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,250),2)\n",
    "\n",
    "#showImage( np.hstack((med,two))   )\n",
    "joined_image = np.hstack((orig_img_text,two)   )\n",
    "showImage(joined_image)\n"
   ]
  },
  {
   "source": [
    "- Det kändes som en svår bild antingen blir det för mycket edges eller så för lite. Noisen fick man bort lätt med ett median filter. \n",
    "- Efter det testade jag med CLAHE som gav ett bättre djup på bilden.\n",
    "- Sedan testade jag med laplacianfilter,hpf,gaussianfilter, sobel. Jag hade flera resultat jag tyckte var helt bra men jag höll på lite för länge och glömde bort att spara alla bra resultat.\n",
    "- Problemen jag stöter på är att om man vill att alla edges är synliga kommer det för mycket extra linjer här och där. \n",
    "- Men om man är för argressiv med thresholds och dylikt så försvinner för mycket linjer helt och hållet.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Median blur 13 -> clipLimit = 3,tileGridSize=(5,5) -> canny 100,170,aperture=5,true\n",
    "- Till den här bilden använde jag mig av CLAHE med clipLimit=3, tileGridSize=(5,5) och sedan canny med tresholds (100,170) och aperture=5 samt l2gradiant på False\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "![](bild2.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}